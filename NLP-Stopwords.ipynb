{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4f79d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b02c2852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91934\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88bceb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "para='Stopwords play a crucial role in natural language processing (NLP) as they are the most common words in any language, such as \"is,\" \"the,\" \"and,\" \"of,\" and \"in.\" These words are often filtered out during text processing because they do not contribute significantly to the meaning of a sentence. By removing stopwords, we can reduce the size of the data and focus on the most relevant words that carry semantic value. This is especially useful in tasks like text classification, sentiment analysis, and information retrieval, where reducing noise improves accuracy and efficiency. Libraries like NLTK and SpaCy provide built-in stopword lists for various languages, making it easy to clean text data. However, the decision to remove stopwords depends on the application; for example, in some contexts, stopwords may hold grammatical or contextual importance. Custom stopword lists can also be created to adapt to specific datasets. Overall, understanding and handling stopwords effectively is a key step in preparing high-quality text data for NLP.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de11a375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('English')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cba69b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24156382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Stopwords play a crucial role in natural language processing (NLP) as they are the most common words in any language, such as \"is,\" \"the,\" \"and,\" \"of,\" and \"in.\"', 'These words are often filtered out during text processing because they do not contribute significantly to the meaning of a sentence.', 'By removing stopwords, we can reduce the size of the data and focus on the most relevant words that carry semantic value.', 'This is especially useful in tasks like text classification, sentiment analysis, and information retrieval, where reducing noise improves accuracy and efficiency.', 'Libraries like NLTK and SpaCy provide built-in stopword lists for various languages, making it easy to clean text data.', 'However, the decision to remove stopwords depends on the application; for example, in some contexts, stopwords may hold grammatical or contextual importance.', 'Custom stopword lists can also be created to adapt to specific datasets.', 'Overall, understanding and handling stopwords effectively is a key step in preparing high-quality text data for NLP.']\n"
     ]
    }
   ],
   "source": [
    "sent=nltk.sent_tokenize(para)\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60ed74a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3235247a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37163174",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sent)):\n",
    "    words=nltk.word_tokenize(sent[i])\n",
    "    words=[stemmer.stem(word) for word in words if word not in set(stopwords.words('English'))]\n",
    "    sent[i]=' ' .join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45d0057a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"stopword play crucial role natur languag process ( nlp ) common word languag , `` , '' `` , '' `` , '' `` , '' `` . ''\",\n",
       " 'these word often filter text process contribut significantli mean sentenc .',\n",
       " 'by remov stopword , reduc size data focu relev word carri semant valu .',\n",
       " 'thi especi use task like text classif , sentiment analysi , inform retriev , reduc nois improv accuraci effici .',\n",
       " 'librari like nltk spaci provid built-in stopword list variou languag , make easi clean text data .',\n",
       " 'howev , decis remov stopword depend applic ; exampl , context , stopword may hold grammat contextu import .',\n",
       " 'custom stopword list also creat adapt specif dataset .',\n",
       " 'overal , understand handl stopword effect key step prepar high-qual text data nlp .']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11d7354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f58003e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "sbs=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50390e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sent)):\n",
    "    words=nltk.word_tokenize(sent[i])\n",
    "    words=[sbs.stem(word) for word in words if word not in set(stopwords.words('English'))]\n",
    "    sent[i]=' ' .join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c765be30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stopword play crucial role natur languag process ( nlp ) common word languag , `` , `` `` , `` `` , `` `` , `` `` . ``',\n",
       " 'word often filter text process contribut signif mean sentenc .',\n",
       " 'remov stopword , reduc size data focu relev word carri semant valu .',\n",
       " 'thi especi use task like text classif , sentiment analysi , inform retriev , reduc noi improv accuraci effici .',\n",
       " 'librari like nltk spaci provid built-in stopword list variou languag , make easi clean text data .',\n",
       " 'howev , deci remov stopword depend applic ; exampl , context , stopword may hold grammat contextu import .',\n",
       " 'custom stopword list also creat adapt specif dataset .',\n",
       " ', understand handl stopword effect key step prepar high-qual text data nlp .']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3aa83121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\91934\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f3e78e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6948fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lem=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd908b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sent)):\n",
    "    words=nltk.word_tokenize(sent[i])\n",
    "    words=[lem.lemmatize(word.lower(),pos='v') for word in words if word not in set(stopwords.words('English'))]\n",
    "    sent[i]=' ' .join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9c26ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stopword play crucial role natur languag process ( nlp ) common word languag , `` , `` `` , `` `` , `` `` , `` `` . ``',\n",
       " 'word often filter text process contribut signif mean sentenc .',\n",
       " 'remov stopword , reduc size data focu relev word carri semant valu .',\n",
       " 'thi especi use task like text classif , sentiment analysi , inform retriev , reduc noi improv accuraci effici .',\n",
       " 'librari like nltk spaci provid built-in stopword list variou languag , make easi clean text data .',\n",
       " 'howev , deci remov stopword depend applic ; exampl , context , stopword may hold grammat contextu import .',\n",
       " 'custom stopword list also creat adapt specif dataset .',\n",
       " ', understand handl stopword effect key step prepar high-qual text data nlp .']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fb6963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
